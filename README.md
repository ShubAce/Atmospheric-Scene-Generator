# Atmospheric Scene Generator ğŸŒ†

<div align="center">
  <strong>A Multi-Sensory AI Art Director</strong>  
</div>

<br>

A web application that transforms textual descriptions of scenes, memories, or moods into immersive, multi-sensory vignettes. Each experience includes a generated image, a natural-sounding voiceover, and an ambient soundscape â€” all orchestrated intelligently by AI.

This project acts as an **AI Art Director**, deconstructing user input and coordinating multiple services to craft a cohesive and atmospheric audio-visual narrative.

---

## âœ¨ Features

- **ğŸï¸ Text-to-Vignette:** Converts a short prompt into a complete multi-modal scene.
- **ğŸ§  AI-Powered Art Direction:** Uses a Large Language Model (Llama 3 via Groq) to generate structured prompts for image, voice, and audio generation.
- **ğŸ§ Multi-Modal Output:** Produces a high-res image, narrative voiceover, and ambient soundscape.
- **ğŸŒ Modern Web Interface:** Clean, responsive UI styled with Tailwind CSS.
- **ğŸ§© API-First Design:** Powered by a modular FastAPI backend.

---

## ğŸ› ï¸ Tech Stack

| Category     | Technology / Service                         |
|--------------|-----------------------------------------------|
| Frontend     | HTML5, Tailwind CSS, JavaScript              |
| Backend      | Python 3.9+, FastAPI, Uvicorn                |
| AI/ML        | LangChain, langchain-groq, pydub             |
| APIs         | Groq, Hugging Face Inference, ElevenLabs, Freesound |
| System Tools | FFmpeg (required by `pydub`)                 |

---

## ğŸš€ Getting Started

Follow these steps to get the project running locally.

### 1. Prerequisites

- **Python 3.9+**
- **FFmpeg:** Required for audio processing via `pydub`.  
  - Download and install: [https://ffmpeg.org/download.html](https://ffmpeg.org/download.html)
  - Ensure it's added to your system's `PATH`.

---

### 2. Clone the Repository

```bash
git clone https://github.com/your-username/atmospheric-scene-generator.git
cd atmospheric-scene-generator

cd backend

# Create a virtual environment
python -m venv venv

# Activate the virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

mv .env.example .env

# .env

# Get from https://console.groq.com/
GROQ_API_KEY="gr_..."

# Get from https://huggingface.co/settings/tokens
HF_API_TOKEN="hf_..."

# Get from https://elevenlabs.io/
ELEVENLABS_API_KEY="..."

# Get from https://freesound.org/home/app_credentials/
FREESOUND_API_KEY="..."

cd backend
source venv/bin/activate  # or activate your virtual environment
python main.py

http://localhost:8000

atmospheric-scene-generator/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/endpoints.py      # FastAPI routes
â”‚   â”‚   â”œâ”€â”€ services/             # Core scene generation logic
â”‚   â”‚   â””â”€â”€ config.py             # Loads and manages API keys
â”‚   â”œâ”€â”€ main.py                   # Entry point for FastAPI server
â”‚   â””â”€â”€ requirements.txt          # Python dependencies
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html                # Main UI (styled with Tailwind CSS)
â”‚   â””â”€â”€ js/main.js                # Core frontend logic
â”‚
â”œâ”€â”€ generated_files/              # Stores generated media temporarily
â”œâ”€â”€ .env                          # Your API keys (not tracked by Git)
â”œâ”€â”€ .env.example                  # Template file for API keys
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                     # Youâ€™re reading it
